{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "810fed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "import selfies as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f92fe1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../data/tokenizers_selfies/moses_selfies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "345e39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies1 = pd.read_csv(\"../data/generated/moses_SELFIES_1_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17ca533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_shit(k):\n",
    "    return isinstance(k,float)\n",
    "selfies1[\"not valid\"] =selfies1[\"SELFIES\"].apply(is_shit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a5c42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies1 = selfies1[ selfies1[\"not valid\"]!=True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59d9d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k  in selfies1[\"SMILES\"]:\n",
    "    if isinstance(k,float):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a3c15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flop = []\n",
    "selfies1[\"SELFIES_reformed\"] = selfies1[\"SMILES\"].apply(sf.encoder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d59c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfie_len(k):\n",
    "    return len(tokenizer.tokenize(k))\n",
    "\n",
    "def selfie_tokenization(k):\n",
    "    return tokenizer.tokenize(k)\n",
    "\n",
    "selfies1[\"generated_len\"] = selfies1[\"SELFIES\"].apply(selfie_len)\n",
    "selfies1[\"reformed_len\"] = selfies1[\"SELFIES_reformed\"].apply(selfie_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "358f1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies1[\"difference\"] = selfies1[\"generated_len\"]-selfies1[\"reformed_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59739332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validity is : 53.59 %\n"
     ]
    }
   ],
   "source": [
    "valid = len(selfies1[selfies1[\"difference\"]==0])/len(selfies1) * 100\n",
    "print(f\"validity is :{valid: .2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11c06a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token len mean difference in all generated sample :  3.38\n",
      "token len mean difference in the bad sample :  7.27\n"
     ]
    }
   ],
   "source": [
    "mean_difference_tot = selfies1[\"difference\"].mean()\n",
    "mean_difference_onlybad = selfies1[selfies1[\"difference\"]!=0][\"difference\"].mean()\n",
    "print(f\"token len mean difference in all generated sample : {mean_difference_tot : .2f}\")\n",
    "print(f\"token len mean difference in the bad sample : {mean_difference_onlybad : .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de76550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c533531",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m added= []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(l1)):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m l1[k]!=\u001b[43ml2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m+\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43madded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[32m      4\u001b[39m         added.append(l2[k+\u001b[38;5;28mlen\u001b[39m(added)])\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(added)==\u001b[32m0\u001b[39m:\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "added= []\n",
    "index = []\n",
    "for k in range(len(l1)):\n",
    "    if l1[k]!=l2[k+len(added)]:\n",
    "        added.append(l2[k+len(added)])\n",
    "        index.append(len(l1))\n",
    "\n",
    "if len(added)==0:\n",
    "    added = l2[len(l1)+1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies1 =  selfies1[selfies1[\"generated_len\"]!=selfies1[\"reformed_len\"] ]\n",
    "selfies1[\"tokenized_selfies\"] = selfies1[\"SELFIES\"].apply(selfie_tokenization)\n",
    "selfies1[\"tokenized_generated\"] = selfies1[\"SELFIES_reformed\"].apply(selfie_tokenization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
