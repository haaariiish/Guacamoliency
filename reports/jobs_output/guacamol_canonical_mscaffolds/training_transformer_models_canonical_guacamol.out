your current dir is: /workdir/simlab_team/prabakaran/GuacaMoliency
your workdir is: /scratch/simlab_team/105867.torque1.cluster.lbt/
number of nodes: 1
number of cores: 48
your execution environment: node081.cluster.lbt
cuda:0
Training start
{'loss': 4.2742, 'grad_norm': 331740.90625, 'learning_rate': 0.0, 'epoch': 0.0}
{'loss': 2.2276, 'grad_norm': 52307.109375, 'learning_rate': 0.0005965798972890251, 'epoch': 9.76}
{'eval_loss': 3.0754430294036865, 'eval_runtime': 535.7752, 'eval_samples_per_second': 293.702, 'eval_steps_per_second': 18.357, 'epoch': 9.76}
{'loss': 1.3177, 'grad_norm': 58294.578125, 'learning_rate': 0.0005835843483166183, 'epoch': 19.51}
{'eval_loss': 2.2915711402893066, 'eval_runtime': 533.199, 'eval_samples_per_second': 295.121, 'eval_steps_per_second': 18.445, 'epoch': 19.51}
{'loss': 1.1006, 'grad_norm': 40157.64453125, 'learning_rate': 0.0005613500611761501, 'epoch': 29.27}
{'eval_loss': 1.964012622833252, 'eval_runtime': 541.134, 'eval_samples_per_second': 290.793, 'eval_steps_per_second': 18.175, 'epoch': 29.27}
{'loss': 0.9959, 'grad_norm': 41902.87890625, 'learning_rate': 0.000530687088848445, 'epoch': 39.02}
{'eval_loss': 1.766011118888855, 'eval_runtime': 538.9931, 'eval_samples_per_second': 291.948, 'eval_steps_per_second': 18.247, 'epoch': 39.02}
{'loss': 0.9295, 'grad_norm': 49531.28515625, 'learning_rate': 0.0004927125632648335, 'epoch': 48.78}
{'eval_loss': 1.6399892568588257, 'eval_runtime': 540.6783, 'eval_samples_per_second': 291.038, 'eval_steps_per_second': 18.19, 'epoch': 48.78}
{'loss': 0.8799, 'grad_norm': 46846.8359375, 'learning_rate': 0.00044880999528177143, 'epoch': 58.54}
{'eval_loss': 1.5425816774368286, 'eval_runtime': 538.6584, 'eval_samples_per_second': 292.129, 'eval_steps_per_second': 18.258, 'epoch': 58.54}
{'loss': 0.8407, 'grad_norm': 52626.734375, 'learning_rate': 0.0004005788697775394, 'epoch': 68.29}
{'eval_loss': 1.4594080448150635, 'eval_runtime': 536.5254, 'eval_samples_per_second': 293.291, 'eval_steps_per_second': 18.331, 'epoch': 68.29}
{'loss': 0.8057, 'grad_norm': 47426.21484375, 'learning_rate': 0.00034977637225290867, 'epoch': 78.05}
{'eval_loss': 1.3823676109313965, 'eval_runtime': 541.3962, 'eval_samples_per_second': 290.652, 'eval_steps_per_second': 18.166, 'epoch': 78.05}
{'loss': 0.7739, 'grad_norm': 51327.29296875, 'learning_rate': 0.00029825336998746244, 'epoch': 87.8}
{'eval_loss': 1.3241069316864014, 'eval_runtime': 541.5886, 'eval_samples_per_second': 290.549, 'eval_steps_per_second': 18.16, 'epoch': 87.8}
{'loss': 0.7451, 'grad_norm': 50456.39453125, 'learning_rate': 0.0002478869801247578, 'epoch': 97.56}
{'eval_loss': 1.2714797258377075, 'eval_runtime': 536.4562, 'eval_samples_per_second': 293.329, 'eval_steps_per_second': 18.333, 'epoch': 97.56}
{'loss': 0.7192, 'grad_norm': 50886.3828125, 'learning_rate': 0.0002005121814065863, 'epoch': 107.32}
{'eval_loss': 1.224429965019226, 'eval_runtime': 534.3663, 'eval_samples_per_second': 294.476, 'eval_steps_per_second': 18.405, 'epoch': 107.32}
{'loss': 0.6959, 'grad_norm': 51827.56640625, 'learning_rate': 0.0001578549611189427, 'epoch': 117.07}
{'eval_loss': 1.182080626487732, 'eval_runtime': 539.5718, 'eval_samples_per_second': 291.635, 'eval_steps_per_second': 18.227, 'epoch': 117.07}
{'loss': 0.6752, 'grad_norm': 54420.7734375, 'learning_rate': 0.00012146943288055413, 'epoch': 126.83}
{'eval_loss': 1.1507898569107056, 'eval_runtime': 537.771, 'eval_samples_per_second': 292.612, 'eval_steps_per_second': 18.288, 'epoch': 126.83}
{'loss': 0.6581, 'grad_norm': 51991.6640625, 'learning_rate': 9.268121623668278e-05, 'epoch': 136.59}
{'eval_loss': 1.1273292303085327, 'eval_runtime': 537.0779, 'eval_samples_per_second': 292.989, 'eval_steps_per_second': 18.312, 'epoch': 136.59}
{'loss': 0.6456, 'grad_norm': 54463.1953125, 'learning_rate': 7.253914088704674e-05, 'epoch': 146.34}
{'eval_loss': 1.108603596687317, 'eval_runtime': 538.1691, 'eval_samples_per_second': 292.395, 'eval_steps_per_second': 18.275, 'epoch': 146.34}
{'loss': 0.6363, 'grad_norm': 54256.1171875, 'learning_rate': 6.177703508860261e-05, 'epoch': 156.1}
{'eval_loss': 1.095269799232483, 'eval_runtime': 532.0718, 'eval_samples_per_second': 295.746, 'eval_steps_per_second': 18.484, 'epoch': 156.1}
{'train_runtime': 29055.664, 'train_samples_per_second': 877.543, 'train_steps_per_second': 1.143, 'train_loss': 0.9052280836076622, 'epoch': 161.95}
Data from this directory : data/training_data/guacamol_canonical.csv
Tokenizer from this directory : data/tokenizers/guacamol_canonical_corrected
log files are in this directory : reports/logs/guacamol_canonical_mscaffolds/1
Model and checkpoint of training has been save in this directory : models/trained_guacamol_canonical_mscaffolds/1
END OF train.py
