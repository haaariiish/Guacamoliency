{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.01943634596696,
  "eval_steps": 2000,
  "global_step": 41200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00048590864917395527,
      "grad_norm": 424363.40625,
      "learning_rate": 0.0,
      "loss": 3.8975,
      "step": 1
    },
    {
      "epoch": 0.9718172983479106,
      "grad_norm": 28980.45703125,
      "learning_rate": 0.0005979854329119042,
      "loss": 2.1615,
      "step": 2000
    },
    {
      "epoch": 0.9718172983479106,
      "eval_loss": 4.4808502197265625,
      "eval_runtime": 358.4373,
      "eval_samples_per_second": 489.829,
      "eval_steps_per_second": 30.616,
      "step": 2000
    },
    {
      "epoch": 1.943634596695821,
      "grad_norm": 30150.796875,
      "learning_rate": 0.00058976077240538,
      "loss": 1.8186,
      "step": 4000
    },
    {
      "epoch": 1.943634596695821,
      "eval_loss": 4.230062484741211,
      "eval_runtime": 359.6814,
      "eval_samples_per_second": 488.135,
      "eval_steps_per_second": 30.51,
      "step": 4000
    },
    {
      "epoch": 2.9154518950437316,
      "grad_norm": 32070.666015625,
      "learning_rate": 0.0005753842085915628,
      "loss": 1.7493,
      "step": 6000
    },
    {
      "epoch": 2.9154518950437316,
      "eval_loss": 4.131921291351318,
      "eval_runtime": 358.2934,
      "eval_samples_per_second": 490.026,
      "eval_steps_per_second": 30.629,
      "step": 6000
    },
    {
      "epoch": 3.887269193391642,
      "grad_norm": 35304.47265625,
      "learning_rate": 0.0005551962210188262,
      "loss": 1.7153,
      "step": 8000
    },
    {
      "epoch": 3.887269193391642,
      "eval_loss": 4.078802108764648,
      "eval_runtime": 359.4226,
      "eval_samples_per_second": 488.486,
      "eval_steps_per_second": 30.532,
      "step": 8000
    },
    {
      "epoch": 4.859086491739553,
      "grad_norm": 34575.453125,
      "learning_rate": 0.0005296749209368645,
      "loss": 1.6941,
      "step": 10000
    },
    {
      "epoch": 4.859086491739553,
      "eval_loss": 4.043136119842529,
      "eval_runtime": 359.1676,
      "eval_samples_per_second": 488.833,
      "eval_steps_per_second": 30.554,
      "step": 10000
    },
    {
      "epoch": 5.830903790087463,
      "grad_norm": 36165.5390625,
      "learning_rate": 0.0004994247282083334,
      "loss": 1.6791,
      "step": 12000
    },
    {
      "epoch": 5.830903790087463,
      "eval_loss": 4.013866901397705,
      "eval_runtime": 359.0383,
      "eval_samples_per_second": 489.009,
      "eval_steps_per_second": 30.565,
      "step": 12000
    },
    {
      "epoch": 6.802721088435375,
      "grad_norm": 37588.81640625,
      "learning_rate": 0.00046516205685899096,
      "loss": 1.667,
      "step": 14000
    },
    {
      "epoch": 6.802721088435375,
      "eval_loss": 3.9891178607940674,
      "eval_runtime": 358.6737,
      "eval_samples_per_second": 489.506,
      "eval_steps_per_second": 30.596,
      "step": 14000
    },
    {
      "epoch": 7.774538386783285,
      "grad_norm": 39885.453125,
      "learning_rate": 0.00042769834827484344,
      "loss": 1.6549,
      "step": 16000
    },
    {
      "epoch": 7.774538386783285,
      "eval_loss": 3.9684269428253174,
      "eval_runtime": 357.5354,
      "eval_samples_per_second": 491.065,
      "eval_steps_per_second": 30.693,
      "step": 16000
    },
    {
      "epoch": 8.746355685131196,
      "grad_norm": 40517.171875,
      "learning_rate": 0.00038792085387036774,
      "loss": 1.6446,
      "step": 18000
    },
    {
      "epoch": 8.746355685131196,
      "eval_loss": 3.9462499618530273,
      "eval_runtime": 358.1778,
      "eval_samples_per_second": 490.184,
      "eval_steps_per_second": 30.638,
      "step": 18000
    },
    {
      "epoch": 9.718172983479105,
      "grad_norm": 47027.01171875,
      "learning_rate": 0.0003467716223510584,
      "loss": 1.6349,
      "step": 20000
    },
    {
      "epoch": 9.718172983479105,
      "eval_loss": 3.9265480041503906,
      "eval_runtime": 359.2473,
      "eval_samples_per_second": 488.725,
      "eval_steps_per_second": 30.547,
      "step": 20000
    },
    {
      "epoch": 10.689990281827017,
      "grad_norm": 44969.8984375,
      "learning_rate": 0.00030522518921406527,
      "loss": 1.6254,
      "step": 22000
    },
    {
      "epoch": 10.689990281827017,
      "eval_loss": 3.9103763103485107,
      "eval_runtime": 358.7206,
      "eval_samples_per_second": 489.442,
      "eval_steps_per_second": 30.592,
      "step": 22000
    },
    {
      "epoch": 11.661807580174926,
      "grad_norm": 47966.5234375,
      "learning_rate": 0.0002642654968655301,
      "loss": 1.6165,
      "step": 24000
    },
    {
      "epoch": 11.661807580174926,
      "eval_loss": 3.8932695388793945,
      "eval_runtime": 359.0889,
      "eval_samples_per_second": 488.94,
      "eval_steps_per_second": 30.561,
      "step": 24000
    },
    {
      "epoch": 12.633624878522838,
      "grad_norm": 47226.60546875,
      "learning_rate": 0.0002248625919544957,
      "loss": 1.607,
      "step": 26000
    },
    {
      "epoch": 12.633624878522838,
      "eval_loss": 3.8765485286712646,
      "eval_runtime": 359.1056,
      "eval_samples_per_second": 488.917,
      "eval_steps_per_second": 30.559,
      "step": 26000
    },
    {
      "epoch": 13.60544217687075,
      "grad_norm": 49562.83203125,
      "learning_rate": 0.0001879496517994406,
      "loss": 1.5978,
      "step": 28000
    },
    {
      "epoch": 13.60544217687075,
      "eval_loss": 3.8631298542022705,
      "eval_runtime": 358.451,
      "eval_samples_per_second": 489.81,
      "eval_steps_per_second": 30.615,
      "step": 28000
    },
    {
      "epoch": 14.577259475218659,
      "grad_norm": 50526.43359375,
      "learning_rate": 0.00015440088398959765,
      "loss": 1.589,
      "step": 30000
    },
    {
      "epoch": 14.577259475218659,
      "eval_loss": 3.8465211391448975,
      "eval_runtime": 358.982,
      "eval_samples_per_second": 489.086,
      "eval_steps_per_second": 30.57,
      "step": 30000
    },
    {
      "epoch": 15.54907677356657,
      "grad_norm": 52365.515625,
      "learning_rate": 0.00012501082256385904,
      "loss": 1.5814,
      "step": 32000
    },
    {
      "epoch": 15.54907677356657,
      "eval_loss": 3.8327109813690186,
      "eval_runtime": 359.6323,
      "eval_samples_per_second": 488.201,
      "eval_steps_per_second": 30.514,
      "step": 32000
    },
    {
      "epoch": 16.52089407191448,
      "grad_norm": 56930.1640625,
      "learning_rate": 0.00010047551109497921,
      "loss": 1.5751,
      "step": 34000
    },
    {
      "epoch": 16.52089407191448,
      "eval_loss": 3.822600841522217,
      "eval_runtime": 358.3424,
      "eval_samples_per_second": 489.959,
      "eval_steps_per_second": 30.624,
      "step": 34000
    },
    {
      "epoch": 17.49271137026239,
      "grad_norm": 54005.14453125,
      "learning_rate": 8.137601831929293e-05,
      "loss": 1.569,
      "step": 36000
    },
    {
      "epoch": 17.49271137026239,
      "eval_loss": 3.8136956691741943,
      "eval_runtime": 358.7821,
      "eval_samples_per_second": 489.358,
      "eval_steps_per_second": 30.587,
      "step": 36000
    },
    {
      "epoch": 18.464528668610303,
      "grad_norm": 54489.59765625,
      "learning_rate": 6.816467671058468e-05,
      "loss": 1.564,
      "step": 38000
    },
    {
      "epoch": 18.464528668610303,
      "eval_loss": 3.8075027465820312,
      "eval_runtime": 358.7275,
      "eval_samples_per_second": 489.433,
      "eval_steps_per_second": 30.591,
      "step": 38000
    },
    {
      "epoch": 19.43634596695821,
      "grad_norm": 54082.03125,
      "learning_rate": 6.115436990938195e-05,
      "loss": 1.5602,
      "step": 40000
    },
    {
      "epoch": 19.43634596695821,
      "eval_loss": 3.802180290222168,
      "eval_runtime": 357.9541,
      "eval_samples_per_second": 490.49,
      "eval_steps_per_second": 30.658,
      "step": 40000
    }
  ],
  "logging_steps": 2000,
  "max_steps": 41200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 21,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.1962419013632e+16,
  "train_batch_size": 768,
  "trial_name": null,
  "trial_params": null
}
